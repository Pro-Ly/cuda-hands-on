\section{内存架构和数据局部性}
到目前为止，我们已经学习了如何编写 CUDA 内核函数以及如何配置和协调大量线程的执行。 我们还研究了当前 GPU 硬件的计算架构以及如何调度线程在该硬件上执行。 在本章中，我们将重点关注 GPU 的片上内存架构，并开始研究如何组织和定位数据，以便大量线程进行高效访问。 到目前为止，我们研究的 CUDA 内核可能只能实现底层硬件潜在速度的一小部分。 这种糟糕的性能是因为通常使用片外 DRAM 实现的全局存储器往往具有较长的访问延迟（数百个时钟周期）和有限的访问带宽。 虽然拥有许多可供执行的线程理论上可以容忍较长的内存访问延迟，但人们很容易遇到这样一种情况：全局内存访问路径中的流量拥塞导致除了极少数线程之外的所有线程都无法取得进展，从而导致某些核心陷入困境。 流式多处理器 (SM) 空闲。 为了避免这种拥塞，GPU 提供了许多额外的片上内存资源来访问数据，从而消除了进出全局内存的大部分流量。 在本章中，我们将研究如何使用不同的内存类型来提高 CUDA 内核的执行性能。