\section{CUDA 动态并行}
CUDA 动态并行性是 CUDA 编程模型的扩展，它使内核能够调用其他内核，从而允许在设备上执行的线程启动新的线程网格。 在 CUDA 的早期版本中，网格只能从主机代码启动。 涉及递归、不规则循环结构、时空变化或其他不适合平面和单级并行性的结构的算法需要通过主机的多个内核调用来实现，这增加了主机的负担、数量 主机设备通信的数量以及总执行时间。 在某些情况下，程序员诉诸循环序列化和其他笨拙的技术来支持这些算法需求，但以软件可维护性为代价。 对动态并行性的支持允许动态发现新工作的算法来准备和启动新网格，而不会增加主机负担或影响软件可维护性。 本章介绍了支持动态并行性的 CUDA 扩展功能，包括对 CUDA 编程接口的修改和添加，以及利用这种附加功能的指南和最佳实践。

\subsection{背景}
许多现实世界的应用程序采用的算法要么具有跨空间的工作变化，要么随着时间的推移动态变化的工作量。 例如，图 21.1 显示了一个湍流模拟示例，其中所需的建模细节水平随空间和时间的不同而变化。 随着燃烧流从左向右移动，活动范围和强度增加。 模型右侧建模所需的细节级别远高于模型左侧。 一方面，使用固定的精细网格会产生过多的工作，而模型的左侧却没有任何增益。 另一方面，使用固定的粗网格会牺牲模型右侧太多的精度。 理想情况下，应该对模型中需要更多细节的部分使用精细网格，对不需要更多细节的部分使用粗网格。

到目前为止，我们假设所有内核都是从主机代码调用的。 线程网格完成的工作量是在调用内核函数时预先确定的。 对于内核代码的单程序、多数据编程风格，让线程块使用不同的网格间距即使不是极其困难，也是乏味的。 因此，这种限制有利于使用固定且统一（规则）的网格系统。 为了达到所需的精度，如图 21.1 右上部分所示，这种固定网格方法通常需要适应模型中要求最高的部分，并维护不必要的额外数据，并在以下部分执行不必要的额外工作： 不需要那么多细节。

更理想的方法如图 21.1 右下部分的动态网格所示。 当仿真算法检测到模型某些区域中快速变化的仿真量时，它会细化这些区域中的网格以达到所需的精度水平。 对于没有表现出如此密集活动的区域，不需要进行这种细化。 因此，该算法可以动态地将更多计算资源引导到从额外工作中受益的模型区域。

图 21.2 显示了没有动态并行性的系统和另一个具有动态并行性的系统相对于图 21.1 中的仿真模型的行为的概念比较。 如果没有动态并行性，主机线程必须启动所有网格。 如果发现新的工作，例如在网格执行期间细化模型中的某个区域，则网格需要终止，向主机报告，并让主机启动新的网格。 这如图 21.2A 所示，其中主机启动一个网格，在其终止后从该网格接收信息，并为已完成的网格发现的任何新工作启动后续网格。 该图描绘了相继启动的后续网格； 然而，可以应用复杂的优化，例如在不同的流中启动独立的网格或将它们组合起来以便它们可以并行运行。

图 21.2B 显示，通过动态并行，发现新工作的线程可以继续并启动网格来完成工作。 在我们的示例中，当线程发现模型中的某个区域需要细化时，它可以启动一个新网格来对细化区域执行计算，而无需终止网格、向主机报告并让 主机启动新网格。

\subsection{动态并行概述}

\subsection{总结}
CUDA 动态并行性扩展了 CUDA 编程模型，允许内核调用其他内核。 这允许每个线程动态地发现工作并根据新发现的工作量启动新的网格。 它还支持线程动态分配设备内存。 正如我们在贝塞尔曲线计算示例中所示，这些扩展可以实现线程和块之间更好的工作平衡以及更有效的内存使用。 CUDA 动态并行性还可以帮助程序员实现递归算法，如四叉树示例所示。

除了确保更好的工作平衡之外，动态并行性在可编程性方面还提供了许多优势。 但是，请务必记住，启动具有少量线程的网格可能会导致 GPU 资源的严重利用不足。 一般建议是启动具有多个块的子网格，或者如果块的数量很小，则至少启动具有多个线程的块。

类似地，嵌套并行性可以看作是树处理的一种形式，当树节点很厚（即每个节点部署许多线程）和/或当分支度很大（即每个父节点都有 很多孩子）。 由于嵌套深度受到硬件的限制，只能有效地实现相对较浅的树。

为了有效地使用动态并行性，程序员需要了解内存内容的可见性、挂起的启动计数和流等细节。 在动态并行性中仔细使用父级和子级之间的内存和流对于正确执行并在启动子网格时实现预期的并行性水平至关重要。